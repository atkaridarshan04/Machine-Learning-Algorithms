{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66ba86f3-cd5f-4a9a-bf1a-d60cd4005351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d8ae785-9a35-4546-82a9-dd1484f159bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1,  -1,  -1,  -1,   0,  -1],\n",
       "       [ -1,  -1,  -1,   0,  -1, 100],\n",
       "       [ -1,  -1,  -1,   0,  -1,  -1],\n",
       "       [ -1,   0,   0,  -1,   0,  -1],\n",
       "       [ -1,   0,   0,  -1,  -1, 100],\n",
       "       [ -1,   0,  -1,  -1,   0, 100]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R = Reward Matrix\n",
    "R = np.array([[-1, -1, -1, -1, 0, -1],\n",
    "              [-1, -1, -1, 0, -1, 100],\n",
    "              [-1, -1, -1, 0, -1, -1],\n",
    "              [-1, 0, 0, -1, 0, -1],\n",
    "              [-1, 0, 0, -1, -1, 100],\n",
    "              [-1, 0, -1, -1, 0, 100]])\n",
    "R\n",
    "# -1 indicates the null value\n",
    "# 0 indicates that there is no direct connection between that two nodes\n",
    "# 100 indicates that there is direct connection between that nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e8788ba-e2f7-4b39-940a-c13961b6b48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q = Action Value\n",
    "Q = np.array(np.zeros([6,6]))\n",
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871f6373-dbe9-4003-b8f3-fec00123d5b3",
   "metadata": {},
   "source": [
    "### Defining Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "072c93ed-6df1-4a6e-a7c9-8dbc258d49ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.8 # discount factor\n",
    "# gamma ranges btn 0 to 1, more the gamma is close to 0 the agent will exploit \n",
    "# and more the gamma value is close to 1 the agent will explore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808db333-0b1e-4c04-86a1-11296396f623",
   "metadata": {},
   "source": [
    "### Getting all available actions for particular state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8d20799-6757-480c-9c9d-84b8fc301546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function return all available action in the state given as an argument\n",
    "def available_actions(state):\n",
    "    current_state_row = R[state, :]\n",
    "    av_act = np.where(current_state_row >= 0) [0] # returns a tuple containing the indices where the condition is True.\n",
    "    # Since we are interested in the column indices, we use [0] to access the first element of the tuple, which contains these indices.\n",
    "    return av_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd6e5df0-585e-4bd1-9f48-b57c73626839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 5]\n"
     ]
    }
   ],
   "source": [
    "initial_state = 1 # Initial State (Usually to be chosen at random)\n",
    "\n",
    "available_act = available_actions(initial_state)\n",
    "print(available_act)\n",
    "# Getting the available action  means what are the possible path for our agent to go further"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0cfac0-eff2-4f12-8e38-b081277090e3",
   "metadata": {},
   "source": [
    "### Choosing which action to be performed by agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4164d661-8c77-4645-80f1-2288e7b87767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function chooses at random which action to be performend within the range of all the available actions\n",
    "def sample_next_action( available_action_range ):\n",
    "    next_action = int(np.random.choice( available_act )) # it choses a any value at random from that array\n",
    "    return next_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1a2a776-3e42-41bf-bf22-45e5af30330b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Sample next action to be performed\n",
    "action = sample_next_action( available_act )\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19db993-970b-4a52-8b38-6b16546dea9c",
   "metadata": {},
   "source": [
    "### Updating Q matrix and Q Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13388cd8-6ea0-4e53-8e1c-10e543cd851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function updates Q matrix and Q Learning Algorithm according to path selected\n",
    "def update_Q( current_state, action, gamma ):\n",
    "    max_index = np.where( Q[action, :] == np.max(Q[action, :])) [0]\n",
    "\n",
    "    if(max_index.shape[0] > 1):\n",
    "        max_index = int(np.random.choice(max_index))\n",
    "    else:\n",
    "        max_index = int(max_index[0])\n",
    "\n",
    "    max_value = Q[action, max_index]\n",
    "\n",
    "    # Q Learning Formula\n",
    "    Q[current_state, action] = R[current_state, action] + gamma * max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe7d9739-2cf0-4d66-befa-55ec8f73dd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Q matrix\n",
    "update_Q(initial_state, action, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c57f5d-4718-4dd5-a613-7f6f40f85973",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb012c67-0536-491a-9f8d-76820854460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training over 10,000 iterations, more-iterations = well trained\n",
    "\n",
    "for i in range(10000):\n",
    "    current_state = np.random.randint(0, Q.shape[0])\n",
    "    available_act = available_actions(current_state)\n",
    "    action = sample_next_action(available_act)\n",
    "    update_Q( current_state, action, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccb5939-e3dc-4d87-a22f-a05f62ec68b8",
   "metadata": {},
   "source": [
    "### Normalize the Trained Q matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "889765bd-e336-4bf9-a7dd-14d935031c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0.,   0., 400.,   0.],\n",
       "       [  0.,   0.,   0., 320.,   0., 500.],\n",
       "       [  0.,   0.,   0., 320.,   0.,   0.],\n",
       "       [  0., 400., 256.,   0., 400.,   0.],\n",
       "       [  0., 400., 256.,   0.,   0., 500.],\n",
       "       [  0., 400.,   0.,   0., 400., 500.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00810c25-295a-4614-bf08-d9a24f31a0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Q matrix:\n",
      "[[0.      0.      0.      0.      0.008   0.     ]\n",
      " [0.      0.      0.      0.0064  0.      0.01   ]\n",
      " [0.      0.      0.      0.0064  0.      0.     ]\n",
      " [0.      0.008   0.00512 0.      0.008   0.     ]\n",
      " [0.      0.008   0.00512 0.      0.      0.01   ]\n",
      " [0.      0.008   0.      0.      0.008   0.01   ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Trained Q matrix:\")\n",
    "print(Q / (np.max(Q) * 100))\n",
    "# normalizes the Q-values by dividing each value in the Q matrix by 100 times the maximum Q-value in the matrix.\n",
    "# This scales the Q-values to be between 0 and 1, making them more interpretable and stable for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb32a53-41ee-46ba-860a-df94d5edcb1a",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1a5910e-408b-4860-b997-b151429a0647",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_state = 2\n",
    "steps = [current_state]\n",
    "\n",
    "while current_state != 5:\n",
    "    next_step_index = np.where(Q[current_state, :] == np.max(Q[current_state, :]))[0]\n",
    "\n",
    "    if next_step_index.shape[0] > 1:\n",
    "        next_step_index = int(np.random.choice(next_step_index))\n",
    "    else:\n",
    "        next_step_index = int(next_step_index[0])\n",
    "\n",
    "    steps.append(next_step_index)\n",
    "    \n",
    "    current_state = next_step_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2fd305-146c-4028-b2dd-c895f04b5ff9",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "598e9e0a-669c-4fbb-b63f-708ce5986418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best sequence path: [2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "print(\"Best sequence path:\", steps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
